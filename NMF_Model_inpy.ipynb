{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11MXwv3DGNSGOR3AVs-7oySl7dVs3CC8L",
      "authorship_tag": "ABX9TyOh9+0U4X4UXW2yFTnLNtpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worldone-web/Team4-Traveler/blob/main/NMF_Model_inpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF 모델을 학습하기 위한 라이브러리들!"
      ],
      "metadata": {
        "id": "cAU8fJ6qtN2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM3XnYRjAwXi",
        "outputId": "a210060c-25e8-418e-8880-c05aef9022ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#라이브러리들을 사용하기 위한 설치작업"
      ],
      "metadata": {
        "id": "BJ5xdIHpBw3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB8LgfPytSMM",
        "outputId": "58b4e986-edd3-43ea-b5d7-3c26ca7f3aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3162734 sha256=7a0e34158f2951b61049c99642421664c6f1cf1adf0db0fc1ad07bd96e45ac63\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import NMF\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n"
      ],
      "metadata": {
        "id": "GlKWwFzMtqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pandas의 DataFrame으로 전환 후 DataSet 변환"
      ],
      "metadata": {
        "id": "3AyT71kjt1oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/G_Project/philadelphia_reviews.csv\")\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5)) # 평점은 1~5 사이로 학습하는 모델\n",
        "data = Dataset.load_from_df(df[['user_id', 'business_id', 'stars']], reader)"
      ],
      "metadata": {
        "id": "RzpabSB0t7Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련세트 80% 테스트세트 20% 나누기"
      ],
      "metadata": {
        "id": "8ZiNxdN1uxL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-3J2CcbiuLGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF 모델 생성 및 학습"
      ],
      "metadata": {
        "id": "aVzCeonRu9Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nmf_model = NMF()\n",
        "nmf_model.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGhx62xcvKA6",
        "outputId": "4c35a521-b585-4e87-c482-1d9c25a4532a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x7db2300fb3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트 세트에 대한 예측 및 모델의 성능을 RMSE로 평가"
      ],
      "metadata": {
        "id": "_Wt-XS_Ru9pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = nmf_model.test(testset)\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA8v9wQlvNoA",
        "outputId": "f73e4969-1775-4a7e-9a4e-9fd76444daee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.3163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3163086789668728"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precision / Recall로 평가\n",
        "pred.r_ui는 제공된 DataSet의 실제 평점 <br>\n",
        "pred.est는 모델이 예측한 평점"
      ],
      "metadata": {
        "id": "oNGJ6shRjyn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# 예측값과 실제값을 추출\n",
        "y_true = np.array([int(pred.r_ui >= 3.5) for pred in predictions])\n",
        "y_pred = np.array([int(pred.est >=3.5) for pred in predictions])\n",
        "\n",
        "# Precision과 Recall 계산\n",
        "precision = precision_score(y_true, y_pred )\n",
        "recall = recall_score(y_true, y_pred )\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "2OnmI-Mf7cmO",
        "outputId": "8633a5f3-841f-4458-9638-13d5f5ab22d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7545029634269744\n",
            "Recall: 0.7705352046139008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[[TN, FP],[FN, TP]]의 혼합배열을 나타내는 코드이다.\n",
        "---\n",
        "혼동 행렬 출력에서는 각 클래스에 해당하는 모든 예측값이 클래스 0에 해당하는 것으로 나타나며, 다른 클래스에 대한 예측값이 없는 것으로 보인다. 0이 아닌 값은 각 클래스를 의미한다.\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w-4k_ULhCsrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "threshold = 3.5\n",
        "y_pred_binary = [1 if pred > threshold else 0 for pred in y_pred]\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_binary)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmeTj8oBCBF8",
        "outputId": "455ceb2b-eeec-4371-9781-efde64b57301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[    0     0     0     0     0     0]\n",
            " [ 6340  8034     0     0     0     0]\n",
            " [ 5848  6416     0     0     0     0]\n",
            " [ 8470 11024     0     0     0     0]\n",
            " [12512 28772     0     0     0     0]\n",
            " [10803 49519     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision / Recall은 이진 분류 문제에서 사용되는 평가 지표이므로 평점 추천과 같은 다중 클래스 평가 문제에는 직접적으로 적용할 수 없다. Precision과 Recall을 계산하기 위해서는 예측값을 이진 분류로 변환해야 합니다.\n",
        "위와 같은 평가방법은 잘못된 평가 방법입니다."
      ],
      "metadata": {
        "id": "1XfvGS-en8zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# 예측값과 실제값을 추출\n",
        "y_true = np.array([pred.r_ui for pred in predictions])\n",
        "y_pred = np.array([pred.est for pred in predictions])\n",
        "\n",
        "# Precision과 Recall 계산\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nGeOJ14HmNtc",
        "outputId": "e6c497b9-7f76-4871-ee87-1c6a73ca8bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a3292c7291bf>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Precision과 Recall 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1952\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \"\"\"\n\u001b[0;32m-> 1954\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1955\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델의 성능 평가 (MSE 계산)\n",
        "MSE는 모델이 예측한 값과 실제 값 간의 차이의 제곱을 평균한 값"
      ],
      "metadata": {
        "id": "VBTmOxi7pq4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1LzmQJD3IMhO42AldpiFBC2cAcht98Yxx\" width=\"500\" height=\"100\"><br>\n",
        "<center/>"
      ],
      "metadata": {
        "id": "7A5yBleZqmYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = accuracy.mse(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW7GQ104ppeH",
        "outputId": "9c0c9899-3cdd-4a7c-951c-698b1605a935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.7327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델의 성능 평가 (MAE 계산)"
      ],
      "metadata": {
        "id": "cu_yo99lqAEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 예측한 값과 실제 값 간의 차이의 절댓값을 평균한 값"
      ],
      "metadata": {
        "id": "Qmu1aG6EsT0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1Xnt8D7SD7XNDNxjB0mlwONFmohEUYr1o\" height=\"100\"><br>\n",
        "<center/>"
      ],
      "metadata": {
        "id": "ieI10U6ir9Wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = accuracy.mae(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlZySEY3p1Vk",
        "outputId": "f037ce76-911c-4c16-eb9b-b77dbc5b13c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE:  1.0246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF 모델에 잠재 요인 수와 학습 에포크 수 지정하여 평가"
      ],
      "metadata": {
        "id": "fA9OT7niHu6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nmf_model = NMF(n_factors=5, n_epochs=5)\n",
        "nmf_model.fit(trainset)\n",
        "predictions = nmf_model.test(testset)\n",
        "\n",
        "# 모델 학습\n",
        "accuracy.rmse(predictions)\n",
        "mse = accuracy.mse(predictions)\n",
        "mae = accuracy.mae(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9EpEk5WG1pT",
        "outputId": "1af3d9e7-c449-4241-ea68-a2177fb9e8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.6090\n",
            "MSE: 2.5887\n",
            "MAE:  1.1624\n"
          ]
        }
      ]
    }
  ]
}